{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebc79329",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values (Random Forest):\n",
      "['L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'L' 'B' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'B' 'L'\n",
      " 'R' 'B' 'B' 'B' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'B' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'B' 'B' 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'L' 'L' 'L'\n",
      " 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'B' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'B' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'R'\n",
      " 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'B' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'B' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R'\n",
      " 'B' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'B' 'R' 'B' 'R' 'R' 'L' 'R' 'R'\n",
      " 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R']\n",
      "Predicted values (Naive Bayes):\n",
      "['L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R'\n",
      " 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'R'\n",
      " 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R']\n",
      "Predicted values (Decision Tree):\n",
      "['R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L'\n",
      " 'L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'L' 'R'\n",
      " 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'R' 'R'\n",
      " 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R']\n",
      "Predicted values (SVM):\n",
      "['L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'R' 'R' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'R'\n",
      " 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'R' 'R'\n",
      " 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R']\n",
      "Predicted values (KNN):\n",
      "['L' 'L' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L' 'R' 'L' 'L' 'L'\n",
      " 'R' 'L' 'B' 'L' 'R' 'L' 'R' 'L' 'R' 'R' 'L' 'R' 'R' 'L' 'L' 'R' 'L' 'L'\n",
      " 'R' 'L' 'R' 'R' 'L' 'B' 'B' 'R' 'L' 'R' 'R' 'R' 'R' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'L' 'R' 'L' 'L' 'R' 'R' 'L' 'R' 'L' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'L'\n",
      " 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'L' 'B' 'L' 'L' 'L' 'R' 'R' 'L' 'R' 'R' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'B' 'R' 'R' 'R' 'R' 'L' 'R' 'R' 'R' 'L' 'L'\n",
      " 'L' 'L' 'L' 'R' 'R' 'R' 'R' 'L' 'R' 'L' 'R' 'L' 'L' 'R' 'L' 'B' 'L' 'R'\n",
      " 'L' 'L' 'R' 'L' 'R' 'R' 'L' 'L' 'L' 'R' 'R' 'R' 'L' 'R' 'R' 'L' 'R' 'R'\n",
      " 'B' 'L' 'R' 'B' 'L' 'R' 'R' 'R' 'L' 'L' 'B' 'R' 'R' 'B' 'R' 'L' 'R' 'R'\n",
      " 'R' 'R' 'R' 'L' 'L' 'L' 'R' 'R']\n",
      "\u001b[1m\n",
      "=>Results of Random Forest Model:\u001b[0m\n",
      "Confusion Matrix: \n",
      " [[ 0  7  6]\n",
      " [ 9 76  0]\n",
      " [ 6  4 80]]\n",
      "Accuracy Score:  82.97872340425532\n",
      "\u001b[1m\n",
      "=>Results of Naive Bayes Model:\u001b[0m\n",
      "Confusion Matrix: \n",
      " [[ 0  9  4]\n",
      " [ 0 83  2]\n",
      " [ 0  1 89]]\n",
      "Accuracy Score:  91.48936170212765\n",
      "\u001b[1m\n",
      "=>Results of Decision Tree Model:\u001b[0m\n",
      "Confusion Matrix: \n",
      " [[ 0  6  7]\n",
      " [ 0 63 22]\n",
      " [ 0 20 70]]\n",
      "Accuracy Score:  70.74468085106383\n",
      "\u001b[1m\n",
      "=>Results of SVM Model:\u001b[0m\n",
      "Confusion Matrix: \n",
      " [[ 0 12  1]\n",
      " [ 0 84  1]\n",
      " [ 0  3 87]]\n",
      "Accuracy Score:  90.95744680851064\n",
      "\u001b[1m\n",
      "=>Results of KNN Model:\u001b[0m\n",
      "Confusion Matrix: \n",
      " [[ 0  6  7]\n",
      " [ 4 79  2]\n",
      " [ 6  6 78]]\n",
      "Accuracy Score:  83.51063829787235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Softwares_Ashish\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "balance_data = pd.read_csv('balance-scale.csv')\n",
    "\n",
    "# Assign Independent and Dependent Variables\n",
    "X = balance_data.values[:, 1:5]\n",
    "Y = balance_data.values[:, 0]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Perform Feature Scaling on dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Training the Random forest model on the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators = 100, criterion=\"entropy\")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Training the Decision Tree model on the Training set\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier(criterion=\"entropy\", random_state=100, max_depth=3, min_samples_leaf=5)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "# Fit SVM to the Training set\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(kernel = 'rbf', random_state = 0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "# Training the K-NN model on the Training set\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Prediction of the Different ML Algorithms\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "print(\"Predicted values (Random Forest):\")\n",
    "print(y_pred_rf)\n",
    "\n",
    "y_pred_nb = nb.predict(X_test)\n",
    "print(\"Predicted values (Naive Bayes):\")\n",
    "print(y_pred_nb)\n",
    "\n",
    "y_pred_dt = dt.predict(X_test)\n",
    "print(\"Predicted values (Decision Tree):\")\n",
    "print(y_pred_dt)\n",
    "\n",
    "y_pred_svm = svm.predict(X_test)\n",
    "print(\"Predicted values (SVM):\")\n",
    "print(y_pred_svm)\n",
    "\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "print(\"Predicted values (KNN):\")\n",
    "print(y_pred_knn)\n",
    "\n",
    "\n",
    "# Results of the Different ML Algorithms\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "#print(\"\\n=>Results of Random Forest Model:\")\n",
    "print(\"\\033[1m\"+\"\\n=>Results of Random Forest Model:\"+\"\\033[0m\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test,y_pred_rf)*100)\n",
    "report_rf = classification_report(y_test, y_pred_rf, output_dict=True)\n",
    "\n",
    "#print(\"\\nResults of Naive Bayes Model:\")\n",
    "print(\"\\033[1m\"+\"\\n=>Results of Naive Bayes Model:\"+\"\\033[0m\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test,y_pred_nb)*100)\n",
    "report_nb = classification_report(y_test, y_pred_nb, output_dict=True)\n",
    "\n",
    "#print(\"\\n=>Results of Decision Tree Model:\")\n",
    "print(\"\\033[1m\"+\"\\n=>Results of Decision Tree Model:\"+\"\\033[0m\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_pred_dt)*100)\n",
    "report_dt = classification_report(y_test, y_pred_dt, output_dict=True)\n",
    "\n",
    "#print(\"\\n=>Results of SVM Model:\")\n",
    "print(\"\\033[1m\"+\"\\n=>Results of SVM Model:\"+\"\\033[0m\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred_svm))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test, y_pred_svm)*100)\n",
    "report_svm = classification_report(y_test, y_pred_svm, output_dict=True)\n",
    "\n",
    "#print(\"\\n=>Results of KNN Model:\")\n",
    "print(\"\\033[1m\"+\"\\n=>Results of KNN Model:\"+\"\\033[0m\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred_knn))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test,y_pred_knn)*100)\n",
    "report_knn = classification_report(y_test, y_pred_knn, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ec1374b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted values (Logistic Regression):\n",
      "[0. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1.\n",
      " 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0.\n",
      " 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
      " 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 0. 1.\n",
      " 0. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
      " 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      " 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0.\n",
      " 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1.\n",
      " 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 1. 0.]\n",
      "\n",
      "Results of Logistic Regression Model:\n",
      "\u001b[1m\n",
      "=>Results of Logistic Regression Model:\u001b[0m\n",
      "Confusion Matrix: \n",
      " [[127  23]\n",
      " [ 36  45]]\n",
      "Accuracy Score:  74.45887445887446\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "\n",
    "# Assign Independent and Dependent Variables\n",
    "X = diabetes.values[:, 0:7]\n",
    "Y = diabetes.values[:, 8]\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=100)\n",
    "\n",
    "# Perform Feature Scaling on dataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "# Training the Logistic Regression model on the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction of the Different ML Algorithms\n",
    "y_pred_lr = model.predict(X_test)\n",
    "print(\"Predicted values (Logistic Regression):\")\n",
    "print(y_pred_lr)\n",
    "\n",
    "# Results of the Different ML Algorithms\n",
    "print(\"\\nResults of Logistic Regression Model:\")\n",
    "print(\"\\033[1m\"+\"\\n=>Results of Logistic Regression Model:\"+\"\\033[0m\")\n",
    "print(\"Confusion Matrix: \\n\",confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"Accuracy Score: \",accuracy_score(y_test,y_pred_lr)*100)\n",
    "report_nb = classification_report(y_test, y_pred_lr, output_dict=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b43bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
